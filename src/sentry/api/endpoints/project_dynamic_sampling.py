import math

from django.utils import timezone
from rest_framework import status
from rest_framework.request import Request
from rest_framework.response import Response

from sentry import features
from sentry.api.bases.project import ProjectEndpoint, ProjectPermission
from sentry.models import Project
from sentry.snuba import discover
from sentry.utils.dates import parse_stats_period


def percentile_fn(data, percentile):
    pecentile_idx = len(data) * percentile
    if pecentile_idx.is_integer():
        return data[int(pecentile_idx)]
    else:
        return data[int(math.ceil(pecentile_idx)) - 1]


class DynamicSamplingPermission(ProjectPermission):
    # ToDo(ahmed): Revisit the permission level for Dynamic Sampling once the requirements are
    #  better defined
    scope_map = {"GET": ["project:write", "project:admin"]}


class ProjectDynamicSamplingDistributionEndpoint(ProjectEndpoint):
    permission_classes = (DynamicSamplingPermission,)

    def get(self, request: Request, project) -> Response:
        if not features.has(
            "organizations:filters-and-sampling", project.organization, actor=request.user
        ):
            return Response(
                {
                    "detail": [
                        "Dynamic sampling feature flag needs to be enabled before you can perform "
                        "this action."
                    ]
                },
                status=404,
            )

        query = request.GET.get("query", "")
        sample_size = request.GET.get("sampleSize", 10)
        distributed_trace = request.GET.get("distributedTrace", "1") == "1"
        stats_period = parse_stats_period(request.GET.get("statsPeriod", "72h"))

        end_time = timezone.now()
        start_time = end_time - stats_period

        # Fetches a random sample of root transactions of size `sample_size` in the last period
        # defined by `stats_period`. The random sample is fetched by ordering by the
        # `random_number` which is generated by a `random_number` function which generates a random
        # number for every row. The goal here is to fetch the transaction ids, their sample rates
        # and their trace ids.
        root_transactions = discover.query(
            selected_columns=[
                "id",
                "trace",
                "count_if(trace.parent_span,equals," '"")',
                "trace.sample_rate",
                "random_number() AS random_number",
            ],
            query=f'{query} count_if(trace.parent_span,equals,""):1 event.type:transaction',
            params={
                "start": start_time,
                "end": end_time,
                "project_id": [project.id],
                "organization_id": project.organization,
            },
            orderby=["-random_number"],
            offset=0,
            limit=sample_size,
            equations=[],
            auto_fields=True,
            auto_aggregations=True,
            allow_metric_aggregates=True,
            use_aggregate_conditions=True,
            transform_alias_to_input_format=True,
            functions_acl=["random_number"],
            referrer="dynamic-sampling.distribution.fetch-parent-transactions",
        )["data"]

        sample_rates = sorted(
            transaction.get("trace.sample_rate") for transaction in root_transactions
        )
        non_null_sample_rates = sorted(
            float(sample_rate) for sample_rate in sample_rates if sample_rate not in {"", None}
        )
        null_sample_rate_percentage = (
            (len(sample_rates) - len(non_null_sample_rates)) / len(sample_rates) * 100
        )

        project_breakdown = None
        if distributed_trace:
            # If the distributedTrace flag was enabled, then we are also interested in fetching
            # the project breakdown of the projects in the trace of the root transaction
            trace_id_list = [transaction.get("trace") for transaction in root_transactions]
            projects_in_org = Project.objects.filter(organization=project.organization).values_list(
                "id", flat=True
            )

            project_breakdown = discover.query(
                selected_columns=["project", "count()"],
                query=f"event.type:transaction trace:[{','.join(trace_id_list)}]",
                params={
                    "start": start_time,
                    "end": end_time,
                    "project_id": list(projects_in_org),
                    "organization_id": project.organization,
                },
                equations=[],
                orderby=[],
                offset=0,
                limit=20,
                auto_fields=True,
                auto_aggregations=True,
                include_equation_fields=False,
                allow_metric_aggregates=True,
                use_aggregate_conditions=True,
                transform_alias_to_input_format=True,
                referrer="dynamic-sampling.distribution.fetch-project-breakdown",
            )["data"]

            # If the number of the projects in the breakdown is greater than 10 projects,
            # then a question needs to be raised on the eligibility of the org for dynamic sampling
            if len(project_breakdown) > 10:
                Response(
                    status=status.HTTP_400_BAD_REQUEST,
                    data={
                        "details": "Way too many projects in the distributed trace's project breakdown"
                    },
                )

        return Response(
            {
                "project_breakdown": project_breakdown,
                "sample_rate": {
                    "sample_size": len(root_transactions),
                    "null_sample_rate_percentage": null_sample_rate_percentage,
                    "p50": percentile_fn(non_null_sample_rates, 0.50),
                    "p90": percentile_fn(non_null_sample_rates, 0.90),
                    "p95": percentile_fn(non_null_sample_rates, 0.95),
                    "p99": percentile_fn(non_null_sample_rates, 0.99),
                    "max": max(non_null_sample_rates),
                    "min": min(non_null_sample_rates),
                    "mean": sum(non_null_sample_rates) / len(non_null_sample_rates),
                },
            }
        )
